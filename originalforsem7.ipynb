{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFJsOQlQk56t"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/Tweet Disaster All CSV File v2.0 - Tweet Disaster All CSV File.csv.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vHcU08ik84M",
        "outputId": "1548e940-5c05-4b4c-dc90-11a59bf35624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-ac7e7741c42e>:1: DtypeWarning: Columns (10,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('/content/Tweet Disaster All CSV File v2.0 - Tweet Disaster All CSV File.csv.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_data = data[['Tweet Text', 'FloodFlag (4:Non_Flood; 5:Flood)']].dropna()\n",
        "filtered_data['FloodFlag (4:Non_Flood; 5:Flood)'] = filtered_data[\n",
        "    'FloodFlag (4:Non_Flood; 5:Flood)'].map({4: 0, 5: 1})"
      ],
      "metadata": {
        "id": "v2xEpd-RlPa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = filtered_data['Tweet Text'].astype(str).values\n",
        "labels = filtered_data['FloodFlag (4:Non_Flood; 5:Flood)'].astype(int).values"
      ],
      "metadata": {
        "id": "2xB1OffklS7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)"
      ],
      "metadata": {
        "id": "0uH9HV9VlXA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Tokenization and padding\n",
        "max_words = 20000  # Maximum number of unique tokens\n",
        "max_len = 50       # Maximum sequence length for padding\n"
      ],
      "metadata": {
        "id": "26mLEZ0MlaJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<UNK>\")\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "metadata": {
        "id": "yK_HLjU0lc8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)"
      ],
      "metadata": {
        "id": "EtBElvgSlfif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=max_len, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "fQtZQv5WljGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = min(max_words, len(tokenizer.word_index) + 1)"
      ],
      "metadata": {
        "id": "G8U-zbjZlm8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Build the BiLSTM model\n",
        "embedding_dim = 128\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
        "    Bidirectional(LSTM(64, return_sequences=False)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHw5JA4WlpeO",
        "outputId": "75cf18b3-9957-4a8b-eebd-fa0efe66f7d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "LDRURrL_lw7a",
        "outputId": "cde96662-d7d8-4ce6-dde1-8be52785052f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 4: Train the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4xLmBy-lxtv",
        "outputId": "26b01c25-0bdc-4cd0-fe8f-c8d626c94ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 148ms/step - accuracy: 0.8949 - loss: 0.3888 - val_accuracy: 0.9308 - val_loss: 0.2471\n",
            "Epoch 2/10\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9326 - loss: 0.2095 - val_accuracy: 0.9333 - val_loss: 0.2397\n",
            "Epoch 3/10\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 150ms/step - accuracy: 0.9654 - loss: 0.0918 - val_accuracy: 0.9013 - val_loss: 0.3469\n",
            "Epoch 4/10\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - accuracy: 0.9950 - loss: 0.0210 - val_accuracy: 0.9207 - val_loss: 0.4624\n",
            "Epoch 5/10\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - accuracy: 0.9980 - loss: 0.0081 - val_accuracy: 0.9013 - val_loss: 0.5799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_val_pad, y_val)\n",
        "print(f\"Validation Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOxrZBEXl23m",
        "outputId": "08452125-1883-4e97-dfa3-5c627fdc5708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9298 - loss: 0.2447\n",
            "Validation Accuracy: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model and tokenizer\n",
        "model.save(\"bilstm_flood_model.h5\")\n",
        "with open(\"tokenizer.json\", \"w\") as f:\n",
        "    f.write(tokenizer.to_json())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjgbVN2_l5XH",
        "outputId": "090f83dd-c3f2-493b-aeb8-95cab694cee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 1: Predict probabilities\n",
        "y_pred_prob = model.predict(X_val_pad)\n",
        "\n",
        "# Step 2: Convert probabilities to binary class labels\n",
        "threshold = 0.5\n",
        "y_pred = (y_pred_prob > threshold).astype(int).flatten()\n",
        "\n",
        "# Step 3: Compare with actual labels\n",
        "correct_predictions = np.sum(y_pred == y_val)\n",
        "total_predictions = len(y_val)\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(f\"Validation Accuracy (manual check): {accuracy:.2f}\")\n",
        "\n",
        "# Step 4: Display a few examples for manual verification\n",
        "for i in range(10):\n",
        "    print(f\"Tweet: {X_val[i]}\")\n",
        "    print(f\"Actual Label: {'Flood-related' if y_val[i] == 1 else 'Non-Flood-related'}\")\n",
        "    print(f\"Predicted Label: {'Flood-related' if y_pred[i] == 1 else 'Non-Flood-related'}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "vT1b-BQPnM8D",
        "outputId": "5a1afaa0-cd75-4be6-cb14-e069d884ece7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "Validation Accuracy (manual check): 0.93\n",
            "Tweet: Kerala is sinking under floods &amp; situation is bad, pray for Kerala @KeralaFloods\n",
            "Actual Label: Flood-related\n",
            "Predicted Label: Flood-related\n",
            "--------------------------------------------------\n",
            "Tweet: Happy Onam to all :-) Low key celebrations as Kerala limps back to life after being battered and bruised by rains .. Lets stand together and utilise the funds for Onam celebrations for flood victims\n",
            "Actual Label: Flood-related\n",
            "Predicted Label: Flood-related\n",
            "--------------------------------------------------\n",
            "Tweet: Kudumbashree workers had been active from the initial days of the flood, making packaged meals available to affected people. #KeralaFloods #KeralaFloodsRelief\n",
            "Actual Label: Flood-related\n",
            "Predicted Label: Flood-related\n",
            "--------------------------------------------------\n",
            "Tweet: There was a warning issued 7 years ago for illegal mining in Kerala. Authorities were warned to stop construction and mining near river! Who was accountable for not following this warning. My guess is Narendra Modi as CM of Kerala in 2011. #KeralaFlood\n",
            "Actual Label: Flood-related\n",
            "Predicted Label: Flood-related\n",
            "--------------------------------------------------\n",
            "Tweet: Uttarakhand received 540 mm rain in Jun 2013: MMS govt sanctioned Rs 7,346 crore for relief and rehabilitation. Kerala received 3000 mm rain - 257% more than usual, the highest since 1930 Centre sanctions Rs 600 crore #Keralafloods #Kerala\n",
            "Actual Label: Flood-related\n",
            "Predicted Label: Flood-related\n",
            "--------------------------------------------------\n",
            "Tweet: #KeralaFloods Ὁ0 Pray for#kerala\n",
            "Actual Label: Flood-related\n",
            "Predicted Label: Flood-related\n",
            "--------------------------------------------------\n",
            "Tweet: #RF distributed 166 dry ration kits in Waalad and 71 dry ration kits in Punchakolly villages of Mananthavady taluk, Wayanad. #RFForKerala #KeralaFlood #KeralaFloodRelief\n",
            "Actual Label: Flood-related\n",
            "Predicted Label: Flood-related\n",
            "--------------------------------------------------\n",
            "Tweet: Dear Rest of Indians, After the flood you might have seen the venom Communists and Jihadis spits out against India. They can’t thank you because they are busy stealing the relief materials from relief camps #CommieThieves #ShamelessCommies #KeralaFlood\n",
            "Actual Label: Flood-related\n",
            "Predicted Label: Flood-related\n",
            "--------------------------------------------------\n",
            "Tweet: The stories about RSS saving victims from #KeralaFloods reminds me about the #balnarendra crocodile tales. Great work of fiction. 50 years later we may hear stories about #boodhaNarendra, PM who swim in the rivers of Kerala to help flood victims.\n",
            "Actual Label: Flood-related\n",
            "Predicted Label: Flood-related\n",
            "--------------------------------------------------\n",
            "Tweet: When the fishermen approached to rescue them from flood water they told them that they are Brahmins, and won’t board the boat. After a few hours the fishermen came back seeing them still in danger. This time they said they will come along only if the\n",
            "Actual Label: Non-Flood-related\n",
            "Predicted Label: Flood-related\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}